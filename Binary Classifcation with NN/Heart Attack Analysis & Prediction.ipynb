{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11X-o0gnxdeE5nA186EV4lW7-IxT5HHTG\n",
      "To: d:\\Document\\Bangkit\\Binary Classifcation with NN\\train.csv\n",
      "100%|██████████| 11.3k/11.3k [00:00<00:00, 609kB/s]\n"
     ]
    }
   ],
   "source": [
    "train_file_id = '11X-o0gnxdeE5nA186EV4lW7-IxT5HHTG'\n",
    "train_output_file = 'train.csv'  \n",
    "\n",
    "train_download_url = f'https://drive.google.com/uc?id={train_file_id}'\n",
    "\n",
    "gdown.download(train_download_url, train_output_file, quiet=False)\n",
    "\n",
    "df = pd.read_csv(train_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0   63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1   37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2   41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3   56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4   57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "\n",
       "   caa  thall  output  \n",
       "0    0      1       1  \n",
       "1    0      2       1  \n",
       "2    0      2       1  \n",
       "3    0      2       1  \n",
       "4    0      2       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 303 entries, 0 to 302\n",
      "Data columns (total 14 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       303 non-null    int64  \n",
      " 1   sex       303 non-null    int64  \n",
      " 2   cp        303 non-null    int64  \n",
      " 3   trtbps    303 non-null    int64  \n",
      " 4   chol      303 non-null    int64  \n",
      " 5   fbs       303 non-null    int64  \n",
      " 6   restecg   303 non-null    int64  \n",
      " 7   thalachh  303 non-null    int64  \n",
      " 8   exng      303 non-null    int64  \n",
      " 9   oldpeak   303 non-null    float64\n",
      " 10  slp       303 non-null    int64  \n",
      " 11  caa       303 non-null    int64  \n",
      " 12  thall     303 non-null    int64  \n",
      " 13  output    303 non-null    int64  \n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 33.3 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====sex=====\n",
      "Unique values in sex: [1 0]\n",
      "Number of unique values in sex: 2\n",
      "Value counts in sex:\n",
      "sex\n",
      "1    207\n",
      "0     96\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====cp=====\n",
      "Unique values in cp: [3 2 1 0]\n",
      "Number of unique values in cp: 4\n",
      "Value counts in cp:\n",
      "cp\n",
      "0    143\n",
      "2     87\n",
      "1     50\n",
      "3     23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====fbs=====\n",
      "Unique values in fbs: [1 0]\n",
      "Number of unique values in fbs: 2\n",
      "Value counts in fbs:\n",
      "fbs\n",
      "0    258\n",
      "1     45\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====restecg=====\n",
      "Unique values in restecg: [0 1 2]\n",
      "Number of unique values in restecg: 3\n",
      "Value counts in restecg:\n",
      "restecg\n",
      "1    152\n",
      "0    147\n",
      "2      4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====exng=====\n",
      "Unique values in exng: [0 1]\n",
      "Number of unique values in exng: 2\n",
      "Value counts in exng:\n",
      "exng\n",
      "0    204\n",
      "1     99\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====slp=====\n",
      "Unique values in slp: [0 2 1]\n",
      "Number of unique values in slp: 3\n",
      "Value counts in slp:\n",
      "slp\n",
      "2    142\n",
      "1    140\n",
      "0     21\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====caa=====\n",
      "Unique values in caa: [0 2 1 3 4]\n",
      "Number of unique values in caa: 5\n",
      "Value counts in caa:\n",
      "caa\n",
      "0    175\n",
      "1     65\n",
      "2     38\n",
      "3     20\n",
      "4      5\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====thall=====\n",
      "Unique values in thall: [1 2 3 0]\n",
      "Number of unique values in thall: 4\n",
      "Value counts in thall:\n",
      "thall\n",
      "2    166\n",
      "3    117\n",
      "1     18\n",
      "0      2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=====output=====\n",
      "Unique values in output: [1 0]\n",
      "Number of unique values in output: 2\n",
      "Value counts in output:\n",
      "output\n",
      "1    165\n",
      "0    138\n",
      "Name: count, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "variables = [col for col in df.columns if df[col].nunique() <= 10]\n",
    "for var in variables:\n",
    "  print(f\"====={var}=====\")\n",
    "  unique_values = df[var].unique()\n",
    "  n_unique_values = df[var].nunique()\n",
    "  value_counts = df[var].value_counts()\n",
    "\n",
    "  print(f\"Unique values in {var}: {unique_values}\")\n",
    "  print(f\"Number of unique values in {var}: {n_unique_values}\")\n",
    "  print(f\"Value counts in {var}:\\n{value_counts}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = [col for col in df.columns if col not in variables]\n",
    "ss = StandardScaler()\n",
    "\n",
    "df[num_columns] = ss.fit_transform(df[num_columns])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [col for col in df.columns if col not in ['output']]\n",
    "target = 'output'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.5496 - loss: 0.6892 - val_accuracy: 0.7869 - val_loss: 0.6416\n",
      "Epoch 2/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6115 - loss: 0.6561 - val_accuracy: 0.8033 - val_loss: 0.5871\n",
      "Epoch 3/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6793 - loss: 0.6140 - val_accuracy: 0.8197 - val_loss: 0.5325\n",
      "Epoch 4/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.6966 - loss: 0.6040 - val_accuracy: 0.8361 - val_loss: 0.4836\n",
      "Epoch 5/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7486 - loss: 0.5355 - val_accuracy: 0.8361 - val_loss: 0.4342\n",
      "Epoch 6/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7670 - loss: 0.5107 - val_accuracy: 0.8525 - val_loss: 0.4016\n",
      "Epoch 7/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7054 - loss: 0.5406 - val_accuracy: 0.8525 - val_loss: 0.3853\n",
      "Epoch 8/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7972 - loss: 0.5094 - val_accuracy: 0.8525 - val_loss: 0.3791\n",
      "Epoch 9/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8178 - loss: 0.4582 - val_accuracy: 0.8689 - val_loss: 0.3782\n",
      "Epoch 10/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8122 - loss: 0.4368 - val_accuracy: 0.8689 - val_loss: 0.3823\n",
      "Epoch 11/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7939 - loss: 0.4435 - val_accuracy: 0.8689 - val_loss: 0.3826\n",
      "Epoch 12/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8100 - loss: 0.4488 - val_accuracy: 0.8033 - val_loss: 0.4104\n",
      "Epoch 13/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8619 - loss: 0.4300 - val_accuracy: 0.8033 - val_loss: 0.4107\n",
      "Epoch 14/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8575 - loss: 0.3871 - val_accuracy: 0.8525 - val_loss: 0.3922\n",
      "Epoch 15/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8484 - loss: 0.3637 - val_accuracy: 0.8525 - val_loss: 0.4044\n",
      "Epoch 16/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8564 - loss: 0.3751 - val_accuracy: 0.8525 - val_loss: 0.4102\n",
      "Epoch 17/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8167 - loss: 0.3961 - val_accuracy: 0.8197 - val_loss: 0.4407\n",
      "Epoch 18/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8770 - loss: 0.3436 - val_accuracy: 0.8525 - val_loss: 0.4295\n",
      "Epoch 19/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8093 - loss: 0.4588 - val_accuracy: 0.8525 - val_loss: 0.4300\n",
      "Epoch 20/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8335 - loss: 0.3935 - val_accuracy: 0.8525 - val_loss: 0.4325\n",
      "Epoch 21/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8432 - loss: 0.3723 - val_accuracy: 0.8525 - val_loss: 0.4205\n",
      "Epoch 22/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8658 - loss: 0.3591 - val_accuracy: 0.8525 - val_loss: 0.4250\n",
      "Epoch 23/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8599 - loss: 0.3926 - val_accuracy: 0.8689 - val_loss: 0.4354\n",
      "Epoch 24/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8284 - loss: 0.3649 - val_accuracy: 0.8197 - val_loss: 0.4531\n",
      "Epoch 25/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8737 - loss: 0.3198 - val_accuracy: 0.8525 - val_loss: 0.4438\n",
      "Epoch 26/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8926 - loss: 0.3079 - val_accuracy: 0.8525 - val_loss: 0.4581\n",
      "Epoch 27/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8671 - loss: 0.2947 - val_accuracy: 0.8525 - val_loss: 0.4705\n",
      "Epoch 28/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8994 - loss: 0.2745 - val_accuracy: 0.8525 - val_loss: 0.4973\n",
      "Epoch 29/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8911 - loss: 0.2965 - val_accuracy: 0.8525 - val_loss: 0.5030\n",
      "Epoch 30/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8610 - loss: 0.3354 - val_accuracy: 0.8525 - val_loss: 0.5067\n",
      "Epoch 31/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8803 - loss: 0.3412 - val_accuracy: 0.8525 - val_loss: 0.5194\n",
      "Epoch 32/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9124 - loss: 0.2585 - val_accuracy: 0.8361 - val_loss: 0.5361\n",
      "Epoch 33/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8962 - loss: 0.2845 - val_accuracy: 0.8525 - val_loss: 0.5424\n",
      "Epoch 34/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8761 - loss: 0.3229 - val_accuracy: 0.8525 - val_loss: 0.5529\n",
      "Epoch 35/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9112 - loss: 0.2569 - val_accuracy: 0.8033 - val_loss: 0.5999\n",
      "Epoch 36/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8890 - loss: 0.2468 - val_accuracy: 0.8525 - val_loss: 0.6089\n",
      "Epoch 37/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9291 - loss: 0.2750 - val_accuracy: 0.8361 - val_loss: 0.6197\n",
      "Epoch 38/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9025 - loss: 0.2307 - val_accuracy: 0.8361 - val_loss: 0.6296\n",
      "Epoch 39/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9034 - loss: 0.2726 - val_accuracy: 0.8525 - val_loss: 0.6366\n",
      "Epoch 40/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8687 - loss: 0.2790 - val_accuracy: 0.8525 - val_loss: 0.6601\n",
      "Epoch 41/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8928 - loss: 0.2761 - val_accuracy: 0.8033 - val_loss: 0.6939\n",
      "Epoch 42/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9066 - loss: 0.2478 - val_accuracy: 0.8525 - val_loss: 0.6688\n",
      "Epoch 43/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9264 - loss: 0.2410 - val_accuracy: 0.8525 - val_loss: 0.6685\n",
      "Epoch 44/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9293 - loss: 0.1795 - val_accuracy: 0.8525 - val_loss: 0.6964\n",
      "Epoch 45/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 60ms/step - accuracy: 0.9228 - loss: 0.2195 - val_accuracy: 0.8525 - val_loss: 0.6977\n",
      "Epoch 46/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8854 - loss: 0.2738 - val_accuracy: 0.8525 - val_loss: 0.6758\n",
      "Epoch 47/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.9185 - loss: 0.2117 - val_accuracy: 0.8525 - val_loss: 0.6870\n",
      "Epoch 48/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 66ms/step - accuracy: 0.9310 - loss: 0.1843 - val_accuracy: 0.8525 - val_loss: 0.6919\n",
      "Epoch 49/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9281 - loss: 0.2190 - val_accuracy: 0.8525 - val_loss: 0.7189\n",
      "Epoch 50/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9184 - loss: 0.2108 - val_accuracy: 0.8361 - val_loss: 0.7560\n",
      "Epoch 51/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9396 - loss: 0.1633 - val_accuracy: 0.8361 - val_loss: 0.7928\n",
      "Epoch 52/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9361 - loss: 0.1795 - val_accuracy: 0.8525 - val_loss: 0.8328\n",
      "Epoch 53/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.8964 - loss: 0.2058 - val_accuracy: 0.8361 - val_loss: 0.8848\n",
      "Epoch 54/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9245 - loss: 0.1642 - val_accuracy: 0.8361 - val_loss: 0.9025\n",
      "Epoch 55/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9149 - loss: 0.2291 - val_accuracy: 0.8361 - val_loss: 0.8963\n",
      "Epoch 56/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9228 - loss: 0.2221 - val_accuracy: 0.8361 - val_loss: 0.8851\n",
      "Epoch 57/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9415 - loss: 0.1568 - val_accuracy: 0.8361 - val_loss: 0.8835\n",
      "Epoch 58/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9286 - loss: 0.1956 - val_accuracy: 0.8361 - val_loss: 0.9093\n",
      "Epoch 59/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9326 - loss: 0.2038 - val_accuracy: 0.8361 - val_loss: 0.9147\n",
      "Epoch 60/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9487 - loss: 0.1545 - val_accuracy: 0.8197 - val_loss: 0.9888\n",
      "Epoch 61/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9408 - loss: 0.1500 - val_accuracy: 0.8361 - val_loss: 1.0148\n",
      "Epoch 62/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9321 - loss: 0.1663 - val_accuracy: 0.8361 - val_loss: 1.0446\n",
      "Epoch 63/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9472 - loss: 0.1461 - val_accuracy: 0.8361 - val_loss: 1.0724\n",
      "Epoch 64/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9211 - loss: 0.1940 - val_accuracy: 0.8197 - val_loss: 1.0556\n",
      "Epoch 65/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9669 - loss: 0.1159 - val_accuracy: 0.8361 - val_loss: 1.0380\n",
      "Epoch 66/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9277 - loss: 0.1720 - val_accuracy: 0.8361 - val_loss: 1.0556\n",
      "Epoch 67/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9383 - loss: 0.1629 - val_accuracy: 0.8197 - val_loss: 1.1459\n",
      "Epoch 68/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9288 - loss: 0.1721 - val_accuracy: 0.8361 - val_loss: 1.0892\n",
      "Epoch 69/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9508 - loss: 0.1386 - val_accuracy: 0.8361 - val_loss: 1.0863\n",
      "Epoch 70/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9340 - loss: 0.1346 - val_accuracy: 0.8361 - val_loss: 1.1240\n",
      "Epoch 71/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9578 - loss: 0.1257 - val_accuracy: 0.8361 - val_loss: 1.1636\n",
      "Epoch 72/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9502 - loss: 0.1225 - val_accuracy: 0.8361 - val_loss: 1.1843\n",
      "Epoch 73/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9464 - loss: 0.1668 - val_accuracy: 0.8361 - val_loss: 1.2404\n",
      "Epoch 74/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9467 - loss: 0.1213 - val_accuracy: 0.8197 - val_loss: 1.2855\n",
      "Epoch 75/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9340 - loss: 0.1396 - val_accuracy: 0.8361 - val_loss: 1.2003\n",
      "Epoch 76/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9525 - loss: 0.1326 - val_accuracy: 0.8361 - val_loss: 1.2329\n",
      "Epoch 77/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9492 - loss: 0.1250 - val_accuracy: 0.8361 - val_loss: 1.3041\n",
      "Epoch 78/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9248 - loss: 0.1861 - val_accuracy: 0.8361 - val_loss: 1.2660\n",
      "Epoch 79/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9664 - loss: 0.0895 - val_accuracy: 0.8361 - val_loss: 1.2911\n",
      "Epoch 80/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9479 - loss: 0.1015 - val_accuracy: 0.8361 - val_loss: 1.3512\n",
      "Epoch 81/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9463 - loss: 0.1236 - val_accuracy: 0.8361 - val_loss: 1.3978\n",
      "Epoch 82/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9539 - loss: 0.1016 - val_accuracy: 0.8361 - val_loss: 1.4337\n",
      "Epoch 83/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9456 - loss: 0.1376 - val_accuracy: 0.8361 - val_loss: 1.3802\n",
      "Epoch 84/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9465 - loss: 0.1843 - val_accuracy: 0.8361 - val_loss: 1.3609\n",
      "Epoch 85/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step - accuracy: 0.9411 - loss: 0.1351 - val_accuracy: 0.8361 - val_loss: 1.4020\n",
      "Epoch 86/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9592 - loss: 0.0935 - val_accuracy: 0.8197 - val_loss: 1.4500\n",
      "Epoch 87/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9629 - loss: 0.1063 - val_accuracy: 0.8361 - val_loss: 1.3638\n",
      "Epoch 88/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9617 - loss: 0.0895 - val_accuracy: 0.8361 - val_loss: 1.3891\n",
      "Epoch 89/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9490 - loss: 0.1388 - val_accuracy: 0.8361 - val_loss: 1.4040\n",
      "Epoch 90/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9714 - loss: 0.0756 - val_accuracy: 0.8361 - val_loss: 1.4335\n",
      "Epoch 91/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9612 - loss: 0.1228 - val_accuracy: 0.8525 - val_loss: 1.4197\n",
      "Epoch 92/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9552 - loss: 0.2141 - val_accuracy: 0.8361 - val_loss: 1.4740\n",
      "Epoch 93/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9455 - loss: 0.1106 - val_accuracy: 0.8361 - val_loss: 1.4666\n",
      "Epoch 94/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9623 - loss: 0.1216 - val_accuracy: 0.8361 - val_loss: 1.5329\n",
      "Epoch 95/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9714 - loss: 0.0836 - val_accuracy: 0.8361 - val_loss: 1.6178\n",
      "Epoch 96/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9745 - loss: 0.0886 - val_accuracy: 0.8361 - val_loss: 1.6212\n",
      "Epoch 97/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9659 - loss: 0.0991 - val_accuracy: 0.8361 - val_loss: 1.6086\n",
      "Epoch 98/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9782 - loss: 0.0869 - val_accuracy: 0.8361 - val_loss: 1.6590\n",
      "Epoch 99/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9728 - loss: 0.0771 - val_accuracy: 0.8361 - val_loss: 1.6667\n",
      "Epoch 100/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9495 - loss: 0.1817 - val_accuracy: 0.8361 - val_loss: 1.6510\n",
      "Epoch 101/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9767 - loss: 0.0636 - val_accuracy: 0.8361 - val_loss: 1.6362\n",
      "Epoch 102/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9738 - loss: 0.0702 - val_accuracy: 0.8361 - val_loss: 1.6444\n",
      "Epoch 103/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9579 - loss: 0.1158 - val_accuracy: 0.8525 - val_loss: 1.6053\n",
      "Epoch 104/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9702 - loss: 0.0844 - val_accuracy: 0.8525 - val_loss: 1.6352\n",
      "Epoch 105/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9706 - loss: 0.0764 - val_accuracy: 0.8361 - val_loss: 1.7126\n",
      "Epoch 106/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9759 - loss: 0.0877 - val_accuracy: 0.8361 - val_loss: 1.8038\n",
      "Epoch 107/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9447 - loss: 0.1366 - val_accuracy: 0.8361 - val_loss: 1.7046\n",
      "Epoch 108/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9792 - loss: 0.0687 - val_accuracy: 0.8525 - val_loss: 1.6643\n",
      "Epoch 109/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9868 - loss: 0.0498 - val_accuracy: 0.8361 - val_loss: 1.7425\n",
      "Epoch 110/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9902 - loss: 0.0494 - val_accuracy: 0.8361 - val_loss: 1.8332\n",
      "Epoch 111/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9576 - loss: 0.1026 - val_accuracy: 0.8361 - val_loss: 1.8552\n",
      "Epoch 112/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9879 - loss: 0.0611 - val_accuracy: 0.8361 - val_loss: 1.8788\n",
      "Epoch 113/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9936 - loss: 0.0327 - val_accuracy: 0.8361 - val_loss: 1.9140\n",
      "Epoch 114/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9843 - loss: 0.0520 - val_accuracy: 0.8361 - val_loss: 1.9532\n",
      "Epoch 115/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9891 - loss: 0.0349 - val_accuracy: 0.8361 - val_loss: 1.9915\n",
      "Epoch 116/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9824 - loss: 0.0393 - val_accuracy: 0.8361 - val_loss: 2.0111\n",
      "Epoch 117/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9919 - loss: 0.0433 - val_accuracy: 0.8361 - val_loss: 2.0777\n",
      "Epoch 118/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9977 - loss: 0.0389 - val_accuracy: 0.8361 - val_loss: 2.1328\n",
      "Epoch 119/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9715 - loss: 0.0755 - val_accuracy: 0.8361 - val_loss: 2.0903\n",
      "Epoch 120/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9940 - loss: 0.0359 - val_accuracy: 0.8361 - val_loss: 2.1129\n",
      "Epoch 121/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9681 - loss: 0.0756 - val_accuracy: 0.8361 - val_loss: 2.1697\n",
      "Epoch 122/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9921 - loss: 0.0443 - val_accuracy: 0.8361 - val_loss: 2.1985\n",
      "Epoch 123/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9668 - loss: 0.0541 - val_accuracy: 0.8361 - val_loss: 2.1939\n",
      "Epoch 124/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9896 - loss: 0.0565 - val_accuracy: 0.8361 - val_loss: 2.1796\n",
      "Epoch 125/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9761 - loss: 0.0582 - val_accuracy: 0.8361 - val_loss: 2.1354\n",
      "Epoch 126/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9755 - loss: 0.0502 - val_accuracy: 0.8525 - val_loss: 2.1598\n",
      "Epoch 127/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9737 - loss: 0.0468 - val_accuracy: 0.8525 - val_loss: 2.2240\n",
      "Epoch 128/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9865 - loss: 0.0401 - val_accuracy: 0.8361 - val_loss: 2.2588\n",
      "Epoch 129/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9808 - loss: 0.0520 - val_accuracy: 0.8361 - val_loss: 2.2460\n",
      "Epoch 130/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9849 - loss: 0.0330 - val_accuracy: 0.8525 - val_loss: 2.2038\n",
      "Epoch 131/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9653 - loss: 0.1124 - val_accuracy: 0.8197 - val_loss: 2.3505\n",
      "Epoch 132/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9753 - loss: 0.0573 - val_accuracy: 0.8033 - val_loss: 2.3974\n",
      "Epoch 133/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9800 - loss: 0.0545 - val_accuracy: 0.8197 - val_loss: 2.4305\n",
      "Epoch 134/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9902 - loss: 0.0387 - val_accuracy: 0.8525 - val_loss: 2.2704\n",
      "Epoch 135/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9700 - loss: 0.0731 - val_accuracy: 0.8689 - val_loss: 2.1283\n",
      "Epoch 136/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9638 - loss: 0.0927 - val_accuracy: 0.8525 - val_loss: 2.0444\n",
      "Epoch 137/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9596 - loss: 0.1392 - val_accuracy: 0.8361 - val_loss: 2.0603\n",
      "Epoch 138/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9824 - loss: 0.0675 - val_accuracy: 0.8525 - val_loss: 2.0396\n",
      "Epoch 139/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9780 - loss: 0.0482 - val_accuracy: 0.8525 - val_loss: 2.0472\n",
      "Epoch 140/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9893 - loss: 0.0304 - val_accuracy: 0.8525 - val_loss: 2.0931\n",
      "Epoch 141/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9755 - loss: 0.0586 - val_accuracy: 0.8361 - val_loss: 2.1847\n",
      "Epoch 142/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9818 - loss: 0.0404 - val_accuracy: 0.8361 - val_loss: 2.2576\n",
      "Epoch 143/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9857 - loss: 0.0393 - val_accuracy: 0.8525 - val_loss: 2.2483\n",
      "Epoch 144/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9903 - loss: 0.0426 - val_accuracy: 0.8689 - val_loss: 2.2793\n",
      "Epoch 145/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9781 - loss: 0.0528 - val_accuracy: 0.8689 - val_loss: 2.3111\n",
      "Epoch 146/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9708 - loss: 0.0631 - val_accuracy: 0.8689 - val_loss: 2.3483\n",
      "Epoch 147/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9861 - loss: 0.0341 - val_accuracy: 0.8525 - val_loss: 2.3822\n",
      "Epoch 148/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9845 - loss: 0.0343 - val_accuracy: 0.8525 - val_loss: 2.4272\n",
      "Epoch 149/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9754 - loss: 0.0910 - val_accuracy: 0.8525 - val_loss: 2.3802\n",
      "Epoch 150/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9784 - loss: 0.0608 - val_accuracy: 0.8361 - val_loss: 2.3237\n",
      "Epoch 151/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9936 - loss: 0.0286 - val_accuracy: 0.8361 - val_loss: 2.3416\n",
      "Epoch 152/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9688 - loss: 0.1225 - val_accuracy: 0.8361 - val_loss: 2.4071\n",
      "Epoch 153/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9845 - loss: 0.0467 - val_accuracy: 0.8361 - val_loss: 2.5291\n",
      "Epoch 154/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9862 - loss: 0.0447 - val_accuracy: 0.8525 - val_loss: 2.5151\n",
      "Epoch 155/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 59ms/step - accuracy: 0.9752 - loss: 0.0412 - val_accuracy: 0.8525 - val_loss: 2.5209\n",
      "Epoch 156/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9702 - loss: 0.0778 - val_accuracy: 0.8361 - val_loss: 2.5153\n",
      "Epoch 157/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 42ms/step - accuracy: 0.9843 - loss: 0.0307 - val_accuracy: 0.8361 - val_loss: 2.5530\n",
      "Epoch 158/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9930 - loss: 0.0339 - val_accuracy: 0.8525 - val_loss: 2.5361\n",
      "Epoch 159/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9889 - loss: 0.0474 - val_accuracy: 0.8361 - val_loss: 2.5728\n",
      "Epoch 160/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9877 - loss: 0.0658 - val_accuracy: 0.8361 - val_loss: 2.5930\n",
      "Epoch 161/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9840 - loss: 0.0441 - val_accuracy: 0.8361 - val_loss: 2.5777\n",
      "Epoch 162/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9964 - loss: 0.0170 - val_accuracy: 0.8361 - val_loss: 2.5979\n",
      "Epoch 163/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9829 - loss: 0.0464 - val_accuracy: 0.8361 - val_loss: 2.7084\n",
      "Epoch 164/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0217 - val_accuracy: 0.8361 - val_loss: 2.7107\n",
      "Epoch 165/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 0.9880 - loss: 0.0352 - val_accuracy: 0.8361 - val_loss: 2.7351\n",
      "Epoch 166/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 281ms/step - accuracy: 0.9867 - loss: 0.0369 - val_accuracy: 0.8361 - val_loss: 2.8024\n",
      "Epoch 167/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 66ms/step - accuracy: 0.9986 - loss: 0.0193 - val_accuracy: 0.8361 - val_loss: 2.8306\n",
      "Epoch 168/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 207ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.8361 - val_loss: 2.8637\n",
      "Epoch 169/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 227ms/step - accuracy: 1.0000 - loss: 0.0079 - val_accuracy: 0.8361 - val_loss: 2.9076\n",
      "Epoch 170/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - accuracy: 1.0000 - loss: 0.0119 - val_accuracy: 0.8361 - val_loss: 2.9307\n",
      "Epoch 171/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9901 - loss: 0.0198 - val_accuracy: 0.8361 - val_loss: 2.9558\n",
      "Epoch 172/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 98ms/step - accuracy: 0.9986 - loss: 0.0340 - val_accuracy: 0.8361 - val_loss: 2.9737\n",
      "Epoch 173/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9902 - loss: 0.0432 - val_accuracy: 0.8361 - val_loss: 3.0161\n",
      "Epoch 174/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 1.0000 - loss: 0.0148 - val_accuracy: 0.8197 - val_loss: 3.1143\n",
      "Epoch 175/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9733 - loss: 0.0456 - val_accuracy: 0.8197 - val_loss: 3.0667\n",
      "Epoch 176/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9743 - loss: 0.0773 - val_accuracy: 0.8033 - val_loss: 3.1202\n",
      "Epoch 177/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9808 - loss: 0.0606 - val_accuracy: 0.8689 - val_loss: 2.9600\n",
      "Epoch 178/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9980 - loss: 0.0174 - val_accuracy: 0.8689 - val_loss: 2.8834\n",
      "Epoch 179/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9906 - loss: 0.0544 - val_accuracy: 0.8525 - val_loss: 2.8053\n",
      "Epoch 180/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9874 - loss: 0.0406 - val_accuracy: 0.8525 - val_loss: 2.7583\n",
      "Epoch 181/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 105ms/step - accuracy: 0.9918 - loss: 0.0283 - val_accuracy: 0.8197 - val_loss: 2.8097\n",
      "Epoch 182/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9923 - loss: 0.0281 - val_accuracy: 0.8197 - val_loss: 2.9229\n",
      "Epoch 183/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 223ms/step - accuracy: 0.9771 - loss: 0.0679 - val_accuracy: 0.8361 - val_loss: 2.8367\n",
      "Epoch 184/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9936 - loss: 0.0152 - val_accuracy: 0.8689 - val_loss: 2.8294\n",
      "Epoch 185/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 100ms/step - accuracy: 0.9675 - loss: 0.0579 - val_accuracy: 0.8361 - val_loss: 2.9057\n",
      "Epoch 186/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 137ms/step - accuracy: 0.9916 - loss: 0.0200 - val_accuracy: 0.8361 - val_loss: 2.9797\n",
      "Epoch 187/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9887 - loss: 0.0412 - val_accuracy: 0.8525 - val_loss: 3.0070\n",
      "Epoch 188/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9900 - loss: 0.0314 - val_accuracy: 0.8361 - val_loss: 3.0715\n",
      "Epoch 189/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 266ms/step - accuracy: 0.9872 - loss: 0.0827 - val_accuracy: 0.8361 - val_loss: 2.9933\n",
      "Epoch 190/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9986 - loss: 0.0118 - val_accuracy: 0.8361 - val_loss: 3.0012\n",
      "Epoch 191/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 96ms/step - accuracy: 0.9853 - loss: 0.0599 - val_accuracy: 0.8525 - val_loss: 2.8983\n",
      "Epoch 192/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 153ms/step - accuracy: 0.9859 - loss: 0.0755 - val_accuracy: 0.8689 - val_loss: 2.8070\n",
      "Epoch 193/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 440ms/step - accuracy: 0.9906 - loss: 0.0476 - val_accuracy: 0.8689 - val_loss: 2.7700\n",
      "Epoch 194/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9953 - loss: 0.0209 - val_accuracy: 0.8689 - val_loss: 2.7660\n",
      "Epoch 195/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 39ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.8525 - val_loss: 2.8190\n",
      "Epoch 196/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9889 - loss: 0.0374 - val_accuracy: 0.8361 - val_loss: 2.8520\n",
      "Epoch 197/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0218 - val_accuracy: 0.8361 - val_loss: 2.8246\n",
      "Epoch 198/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9908 - loss: 0.0315 - val_accuracy: 0.8689 - val_loss: 2.8063\n",
      "Epoch 199/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.8689 - val_loss: 2.8600\n",
      "Epoch 200/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9900 - loss: 0.0232 - val_accuracy: 0.8689 - val_loss: 2.8737\n",
      "Epoch 201/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9916 - loss: 0.0342 - val_accuracy: 0.8689 - val_loss: 2.8980\n",
      "Epoch 202/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9986 - loss: 0.0165 - val_accuracy: 0.8361 - val_loss: 3.0032\n",
      "Epoch 203/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9936 - loss: 0.0176 - val_accuracy: 0.8361 - val_loss: 3.1178\n",
      "Epoch 204/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9944 - loss: 0.0218 - val_accuracy: 0.8197 - val_loss: 3.2081\n",
      "Epoch 205/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9871 - loss: 0.0493 - val_accuracy: 0.8361 - val_loss: 3.1144\n",
      "Epoch 206/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0094 - val_accuracy: 0.8525 - val_loss: 3.0946\n",
      "Epoch 207/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.8525 - val_loss: 3.1029\n",
      "Epoch 208/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.8689 - val_loss: 3.1385\n",
      "Epoch 209/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9843 - loss: 0.0304 - val_accuracy: 0.8361 - val_loss: 3.1799\n",
      "Epoch 210/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9946 - loss: 0.0199 - val_accuracy: 0.8361 - val_loss: 3.2043\n",
      "Epoch 211/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 40ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8361 - val_loss: 3.2263\n",
      "Epoch 212/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9953 - loss: 0.0221 - val_accuracy: 0.8361 - val_loss: 3.1908\n",
      "Epoch 213/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9982 - loss: 0.0083 - val_accuracy: 0.8525 - val_loss: 3.2170\n",
      "Epoch 214/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9936 - loss: 0.0193 - val_accuracy: 0.8525 - val_loss: 3.2152\n",
      "Epoch 215/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9945 - loss: 0.0156 - val_accuracy: 0.8689 - val_loss: 3.2528\n",
      "Epoch 216/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9953 - loss: 0.0207 - val_accuracy: 0.8361 - val_loss: 3.3088\n",
      "Epoch 217/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9936 - loss: 0.0351 - val_accuracy: 0.8361 - val_loss: 3.4043\n",
      "Epoch 218/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9980 - loss: 0.0193 - val_accuracy: 0.8361 - val_loss: 3.4294\n",
      "Epoch 219/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9964 - loss: 0.0098 - val_accuracy: 0.8525 - val_loss: 3.3649\n",
      "Epoch 220/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0056 - val_accuracy: 0.8525 - val_loss: 3.3739\n",
      "Epoch 221/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9901 - loss: 0.0194 - val_accuracy: 0.8525 - val_loss: 3.3544\n",
      "Epoch 222/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9953 - loss: 0.0081 - val_accuracy: 0.8525 - val_loss: 3.3723\n",
      "Epoch 223/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 0.8525 - val_loss: 3.4126\n",
      "Epoch 224/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9936 - loss: 0.0243 - val_accuracy: 0.8525 - val_loss: 3.5316\n",
      "Epoch 225/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0090 - val_accuracy: 0.8361 - val_loss: 3.6333\n",
      "Epoch 226/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0103 - val_accuracy: 0.8361 - val_loss: 3.6769\n",
      "Epoch 227/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.8361 - val_loss: 3.7063\n",
      "Epoch 228/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9986 - loss: 0.0097 - val_accuracy: 0.8361 - val_loss: 3.7393\n",
      "Epoch 229/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9891 - loss: 0.0180 - val_accuracy: 0.8525 - val_loss: 3.7082\n",
      "Epoch 230/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9953 - loss: 0.0144 - val_accuracy: 0.8525 - val_loss: 3.7033\n",
      "Epoch 231/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9529 - loss: 0.1437 - val_accuracy: 0.8525 - val_loss: 3.5633\n",
      "Epoch 232/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9950 - loss: 0.0164 - val_accuracy: 0.8525 - val_loss: 3.5602\n",
      "Epoch 233/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9822 - loss: 0.0385 - val_accuracy: 0.8525 - val_loss: 3.5938\n",
      "Epoch 234/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9917 - loss: 0.0365 - val_accuracy: 0.8525 - val_loss: 3.6190\n",
      "Epoch 235/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9802 - loss: 0.0313 - val_accuracy: 0.8361 - val_loss: 3.6675\n",
      "Epoch 236/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0049 - val_accuracy: 0.8361 - val_loss: 3.7216\n",
      "Epoch 237/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9938 - loss: 0.0109 - val_accuracy: 0.8361 - val_loss: 3.7497\n",
      "Epoch 238/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9933 - loss: 0.0162 - val_accuracy: 0.8361 - val_loss: 3.7475\n",
      "Epoch 239/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9955 - loss: 0.0198 - val_accuracy: 0.8525 - val_loss: 3.6682\n",
      "Epoch 240/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9892 - loss: 0.0145 - val_accuracy: 0.8689 - val_loss: 3.5283\n",
      "Epoch 241/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9935 - loss: 0.0169 - val_accuracy: 0.8689 - val_loss: 3.5794\n",
      "Epoch 242/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9939 - loss: 0.0345 - val_accuracy: 0.8361 - val_loss: 3.6710\n",
      "Epoch 243/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.8361 - val_loss: 3.6954\n",
      "Epoch 244/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9972 - loss: 0.0203 - val_accuracy: 0.8361 - val_loss: 3.7496\n",
      "Epoch 245/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0064 - val_accuracy: 0.8525 - val_loss: 3.7226\n",
      "Epoch 246/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9973 - loss: 0.0106 - val_accuracy: 0.8525 - val_loss: 3.7647\n",
      "Epoch 247/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 54ms/step - accuracy: 0.9906 - loss: 0.0283 - val_accuracy: 0.8361 - val_loss: 4.0304\n",
      "Epoch 248/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9894 - loss: 0.0397 - val_accuracy: 0.8361 - val_loss: 4.0461\n",
      "Epoch 249/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9959 - loss: 0.0291 - val_accuracy: 0.8689 - val_loss: 3.6260\n",
      "Epoch 250/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9727 - loss: 0.1758 - val_accuracy: 0.8525 - val_loss: 3.2837\n",
      "Epoch 251/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9897 - loss: 0.0373 - val_accuracy: 0.8361 - val_loss: 3.2145\n",
      "Epoch 252/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9912 - loss: 0.0407 - val_accuracy: 0.8361 - val_loss: 3.0508\n",
      "Epoch 253/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9936 - loss: 0.0138 - val_accuracy: 0.8689 - val_loss: 2.9574\n",
      "Epoch 254/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9944 - loss: 0.0215 - val_accuracy: 0.8689 - val_loss: 2.9839\n",
      "Epoch 255/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9953 - loss: 0.0179 - val_accuracy: 0.8361 - val_loss: 2.9809\n",
      "Epoch 256/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9874 - loss: 0.0268 - val_accuracy: 0.8525 - val_loss: 3.0123\n",
      "Epoch 257/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9822 - loss: 0.0449 - val_accuracy: 0.8689 - val_loss: 3.0552\n",
      "Epoch 258/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9853 - loss: 0.0484 - val_accuracy: 0.8689 - val_loss: 3.0664\n",
      "Epoch 259/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9933 - loss: 0.0143 - val_accuracy: 0.8361 - val_loss: 3.1145\n",
      "Epoch 260/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9901 - loss: 0.0510 - val_accuracy: 0.8361 - val_loss: 3.1850\n",
      "Epoch 261/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9874 - loss: 0.0406 - val_accuracy: 0.8197 - val_loss: 3.2449\n",
      "Epoch 262/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9935 - loss: 0.0183 - val_accuracy: 0.8197 - val_loss: 3.2840\n",
      "Epoch 263/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9952 - loss: 0.0179 - val_accuracy: 0.8361 - val_loss: 3.2822\n",
      "Epoch 264/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9946 - loss: 0.0204 - val_accuracy: 0.8525 - val_loss: 3.1978\n",
      "Epoch 265/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0132 - val_accuracy: 0.8525 - val_loss: 3.1364\n",
      "Epoch 266/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.8689 - val_loss: 3.1511\n",
      "Epoch 267/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0088 - val_accuracy: 0.8525 - val_loss: 3.1982\n",
      "Epoch 268/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0084 - val_accuracy: 0.8361 - val_loss: 3.2636\n",
      "Epoch 269/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9938 - loss: 0.0330 - val_accuracy: 0.8361 - val_loss: 3.2687\n",
      "Epoch 270/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9986 - loss: 0.0119 - val_accuracy: 0.8689 - val_loss: 3.2670\n",
      "Epoch 271/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9775 - loss: 0.0402 - val_accuracy: 0.8361 - val_loss: 3.3286\n",
      "Epoch 272/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9936 - loss: 0.0138 - val_accuracy: 0.8361 - val_loss: 3.3844\n",
      "Epoch 273/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9824 - loss: 0.0462 - val_accuracy: 0.8361 - val_loss: 3.3610\n",
      "Epoch 274/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9972 - loss: 0.0139 - val_accuracy: 0.8361 - val_loss: 3.3378\n",
      "Epoch 275/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9865 - loss: 0.0232 - val_accuracy: 0.8361 - val_loss: 3.2619\n",
      "Epoch 276/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9924 - loss: 0.0254 - val_accuracy: 0.8361 - val_loss: 3.2240\n",
      "Epoch 277/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0055 - val_accuracy: 0.8361 - val_loss: 3.2092\n",
      "Epoch 278/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9874 - loss: 0.0310 - val_accuracy: 0.8361 - val_loss: 3.2446\n",
      "Epoch 279/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9901 - loss: 0.0385 - val_accuracy: 0.8361 - val_loss: 3.3151\n",
      "Epoch 280/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9857 - loss: 0.0307 - val_accuracy: 0.8361 - val_loss: 3.2964\n",
      "Epoch 281/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9901 - loss: 0.0225 - val_accuracy: 0.8361 - val_loss: 3.3303\n",
      "Epoch 282/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9941 - loss: 0.0188 - val_accuracy: 0.8361 - val_loss: 3.3792\n",
      "Epoch 283/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9802 - loss: 0.0653 - val_accuracy: 0.8361 - val_loss: 3.3499\n",
      "Epoch 284/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9953 - loss: 0.0332 - val_accuracy: 0.8361 - val_loss: 3.3328\n",
      "Epoch 285/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9986 - loss: 0.0125 - val_accuracy: 0.8361 - val_loss: 3.3446\n",
      "Epoch 286/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9917 - loss: 0.0129 - val_accuracy: 0.8361 - val_loss: 3.3570\n",
      "Epoch 287/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0071 - val_accuracy: 0.8361 - val_loss: 3.3948\n",
      "Epoch 288/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9973 - loss: 0.0076 - val_accuracy: 0.8361 - val_loss: 3.4530\n",
      "Epoch 289/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9986 - loss: 0.0067 - val_accuracy: 0.8361 - val_loss: 3.5097\n",
      "Epoch 290/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0053 - val_accuracy: 0.8361 - val_loss: 3.5375\n",
      "Epoch 291/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0054 - val_accuracy: 0.8361 - val_loss: 3.5786\n",
      "Epoch 292/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.8361 - val_loss: 3.6285\n",
      "Epoch 293/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0038 - val_accuracy: 0.8525 - val_loss: 3.6978\n",
      "Epoch 294/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9980 - loss: 0.0074 - val_accuracy: 0.8525 - val_loss: 3.7291\n",
      "Epoch 295/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9964 - loss: 0.0098 - val_accuracy: 0.8525 - val_loss: 3.7325\n",
      "Epoch 296/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9950 - loss: 0.0353 - val_accuracy: 0.8197 - val_loss: 3.7965\n",
      "Epoch 297/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9953 - loss: 0.0106 - val_accuracy: 0.8197 - val_loss: 3.7640\n",
      "Epoch 298/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.8361 - val_loss: 3.7525\n",
      "Epoch 299/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9986 - loss: 0.0084 - val_accuracy: 0.8361 - val_loss: 3.7766\n",
      "Epoch 300/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9900 - loss: 0.0141 - val_accuracy: 0.8525 - val_loss: 3.7718\n",
      "Epoch 301/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9953 - loss: 0.0131 - val_accuracy: 0.8361 - val_loss: 3.7710\n",
      "Epoch 302/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0033 - val_accuracy: 0.8361 - val_loss: 3.7911\n",
      "Epoch 303/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0028 - val_accuracy: 0.8361 - val_loss: 3.7998\n",
      "Epoch 304/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9973 - loss: 0.0040 - val_accuracy: 0.8361 - val_loss: 3.8371\n",
      "Epoch 305/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9964 - loss: 0.0072 - val_accuracy: 0.8361 - val_loss: 3.8790\n",
      "Epoch 306/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9986 - loss: 0.0054 - val_accuracy: 0.8361 - val_loss: 3.9118\n",
      "Epoch 307/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9959 - loss: 0.0149 - val_accuracy: 0.8361 - val_loss: 3.9135\n",
      "Epoch 308/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9973 - loss: 0.0071 - val_accuracy: 0.8361 - val_loss: 3.9048\n",
      "Epoch 309/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0052 - val_accuracy: 0.8525 - val_loss: 3.9209\n",
      "Epoch 310/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0027 - val_accuracy: 0.8525 - val_loss: 3.9316\n",
      "Epoch 311/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9901 - loss: 0.0220 - val_accuracy: 0.8361 - val_loss: 4.0065\n",
      "Epoch 312/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9900 - loss: 0.0163 - val_accuracy: 0.8361 - val_loss: 4.0066\n",
      "Epoch 313/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9991 - loss: 0.0053 - val_accuracy: 0.8361 - val_loss: 4.0269\n",
      "Epoch 314/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9946 - loss: 0.0183 - val_accuracy: 0.8525 - val_loss: 4.0026\n",
      "Epoch 315/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0078 - val_accuracy: 0.8525 - val_loss: 4.0228\n",
      "Epoch 316/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9986 - loss: 0.0108 - val_accuracy: 0.8525 - val_loss: 4.0818\n",
      "Epoch 317/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9936 - loss: 0.0167 - val_accuracy: 0.8525 - val_loss: 4.1447\n",
      "Epoch 318/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9936 - loss: 0.0086 - val_accuracy: 0.8361 - val_loss: 4.1864\n",
      "Epoch 319/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 167ms/step - accuracy: 0.9986 - loss: 0.0114 - val_accuracy: 0.8525 - val_loss: 4.1821\n",
      "Epoch 320/320\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.8689 - val_loss: 4.1120\n",
      "Training completed.\n"
     ]
    }
   ],
   "source": [
    "# Dropout: Mencegah overfitting dengan secara acak menonaktifkan 40% neuron selama pelatihan.\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X.shape[1],)),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid'),  \n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=320, batch_size=32, validation_data=(X_test, y_test))\n",
    "print(\"Training completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "EPOCHS = 50\n",
    "epochs = range(1, EPOCHS + 1)\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(epochs, train_loss, label=\"Training Loss\")\n",
    "plt.plot(epochs, val_loss, label=\"Validation Loss\")\n",
    "\n",
    "plt.title(\"Training and Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
